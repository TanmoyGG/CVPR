# üéì Computer Vision & Pattern Recognition - Complete Project Suite

> **Master Computer Vision from fundamentals to real-world applications: From k-NN classifiers to deep learning face recognition systems.**

---

## üìå Badges

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)
![OpenCV](https://img.shields.io/badge/OpenCV-4.x-green?logo=opencv)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626?logo=jupyter)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Status](https://img.shields.io/badge/Status-Complete-success)

---

## üìñ Project Description

### **Why This Project?**
This repository represents a comprehensive journey through Computer Vision and Pattern Recognition, progressing from classical machine learning algorithms to cutting-edge deep learning architectures. Built as part of academic coursework, it demonstrates both theoretical understanding and practical implementation skills crucial for modern CV applications.

### **What Does It Do?**
The project contains **6 complete implementations** spanning:
- **Classical ML**: k-Nearest Neighbors for image classification
- **Neural Networks**: From-scratch implementations with backpropagation
- **Deep Learning**: CNN-based face recognition and digit detection
- **Transfer Learning**: ResNet50 for high-accuracy face identification
- **Real-Time Systems**: Live webcam integration for attendance tracking
- **Image Processing**: Multi-format preprocessing pipelines (HEIC, DNG, RAW)

Each module is production-ready with comprehensive documentation, error handling, and visualization capabilities.

---

## üõ†Ô∏è Tech Stack

### **Core Technologies**
| Category | Technologies |
|----------|-------------|
| **Languages** | Python 3.8+ |
| **Deep Learning** | TensorFlow 2.x, Keras |
| **Computer Vision** | OpenCV 4.x, PIL/Pillow |
| **Scientific Computing** | NumPy, Pandas, Matplotlib, Seaborn |
| **Image Processing** | pillow-heif, rawpy, imageio |
| **ML Tools** | scikit-learn |

### **Specialized Libraries**
- **Haar Cascade Classifiers** for face detection
- **ImageDataGenerator** for real-time data augmentation
- **ResNet50** pre-trained models (ImageNet)
- **GPU Acceleration** support (CUDA-enabled TensorFlow)

---

## ‚ú® Features

### üéØ **MID-TERM PROJECTS**

#### **Assignment 1: k-NN Image Classifier**
- ‚úÖ **Custom k-NN implementation** from scratch (no scikit-learn)
- ‚úÖ **5-fold cross-validation** with detailed statistics
- ‚úÖ **Distance metrics**: Manhattan (L1) & Euclidean (L2)
- ‚úÖ **Hyperparameter tuning**: Automatic best-K selection
- ‚úÖ **Advanced visualization**: Error bars, scatter plots, decision boundaries
- ‚úÖ **Animal dataset**: Cat, dog, panda classification (32√ó32 grayscale)

#### **Assignment 2: Deep Neural Network from Scratch**
- ‚úÖ **3-hidden-layer architecture** (Input ‚Üí 10 ‚Üí 10 ‚Üí 10 ‚Üí Output)
- ‚úÖ **ReLU activation** for hidden layers (prevents vanishing gradients)
- ‚úÖ **Softmax output** for multi-class classification
- ‚úÖ **Categorical cross-entropy loss**
- ‚úÖ **Full backpropagation** with chain rule implementation
- ‚úÖ **5-class Gaussian dataset** (1000 samples, 2D visualization)
- ‚úÖ **Hyperparameter experiments**: Network size & learning rate comparison
- ‚úÖ **Confusion matrices** + precision/recall/F1 metrics

---

### üéì **FINAL PROJECTS**

#### **1. Image Processing Pipeline**
**Purpose**: Standardize raw images for ML training (multi-format support)

- ‚úÖ **Format support**: JPG, PNG, HEIC, DNG (RAW), JPEG
- ‚úÖ **Auto-cropping**: Center-based square crop
- ‚úÖ **Resizing**: 524√ó524 pixels with LANCZOS interpolation
- ‚úÖ **EXIF handling**: Automatic orientation correction (no flipping)
- ‚úÖ **Batch processing**: Process entire dataset folders
- ‚úÖ **Fallback libraries**: rawpy ‚Üí imageio ‚Üí OpenCV for DNG files
- ‚úÖ **Quality preservation**: 95% JPEG quality, EXIF stripping

---

#### **2. Student Attendance System (CNN from Scratch)**
**Purpose**: Real-time multi-face recognition for attendance tracking

**Architecture**:
- ‚úÖ **Custom CNN**: 3 conv blocks (32‚Üí64‚Üí128 filters)
- ‚úÖ **Batch normalization** after every conv layer
- ‚úÖ **Dropout layers**: Progressive (0.15 ‚Üí 0.2 ‚Üí 0.3)
- ‚úÖ **Dense layers**: 256 ‚Üí 128 ‚Üí NUM_CLASSES
- ‚úÖ **Multi-face detection**: Haar Cascade (2 cascades for fallback)
- ‚úÖ **Real-time processing**: Live webcam feed with bounding boxes
- ‚úÖ **Attendance logging**: CSV export with timestamps
- ‚úÖ **Data augmentation**: Rotation, shift, zoom, flip
- ‚úÖ **Kaggle GPU support**: T4 √ó 2 configuration (24GB memory)

**Metrics**:
- Top-1, Top-5, Top-10 accuracy
- High-confidence filtering (‚â•75%)
- Per-class performance analysis
- Confusion matrix visualization

---

#### **3. Student Attendance System (Transfer Learning)**
**Purpose**: Production-grade face recognition with ResNet50

**Key Features**:
- ‚úÖ **ResNet50 backbone**: Pre-trained on ImageNet
- ‚úÖ **Two-phase training**:
  - Phase 1: Frozen base (transfer learning)
  - Phase 2: Fine-tuning (unfreeze last 50 layers)
- ‚úÖ **Advanced preprocessing**: ResNet-specific normalization
- ‚úÖ **Larger input**: 160√ó160 ‚Üí upscaled to 224√ó224
- ‚úÖ **Robust augmentation**: Brightness, rotation, zoom, shift
- ‚úÖ **Callbacks**: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
- ‚úÖ **High accuracy**: 85%+ confidence threshold
- ‚úÖ **Model persistence**: Save/load trained models

**Performance**:
- Typically achieves **95%+ Top-1 accuracy**
- **99%+ Top-5 accuracy** (correct in top 5 predictions)
- Handles **66 classes** (students) efficiently

---

#### **4. Webcam Digit Detector**
**Purpose**: Real-time handwritten digit recognition (0-9)

**Pipeline**:
- ‚úÖ **MNIST training**: 256 ‚Üí 128 ‚Üí 10 architecture
- ‚úÖ **Real-time preprocessing**:
  - Grayscale conversion
  - Gaussian blur (noise reduction)
  - Otsu's automatic thresholding
  - Morphological operations (opening/closing)
- ‚úÖ **Contour detection**: Find largest digit region
- ‚úÖ **Auto-centering**: Flexible box positioning
- ‚úÖ **Normalization**: 28√ó28 resizing with padding
- ‚úÖ **Live feedback**: Confidence scores, binary preview
- ‚úÖ **IP camera support**: DroidCam integration

**Unique Features**:
- Cyan dashed-look detection box
- Bottom-right corner box placement
- Adaptive thresholding (handles lighting changes)

---

## üöÄ Getting Started

### **Prerequisites**

Ensure you have the following installed:

```bash
# System Requirements
Python 3.8 or higher
pip (Python package manager)
Webcam (for real-time detection projects)
GPU (optional, but recommended for training)
```

For **GPU acceleration** (highly recommended):
- NVIDIA GPU with CUDA 11.2+
- cuDNN 8.1+
- TensorFlow-GPU

---

### **Installation**

#### **1. Clone the Repository**
```bash
git clone https://github.com/TanmoyGG/CVPR.git
cd CVPR
```

#### **2. Create Virtual Environment (Recommended)**
```bash
# Using venv
python -m venv cvpr_env

# Activate (Windows)
cvpr_env\Scripts\activate

# Activate (Linux/Mac)
source cvpr_env/bin/activate
```

#### **3. Install Dependencies**

**For MID projects (Assignments 1 & 2):**
```bash
pip install numpy matplotlib scikit-learn
```

**For FINAL projects (All notebooks):**
```bash
# Core packages
pip install tensorflow opencv-python numpy matplotlib seaborn scikit-learn pandas

# Image processing (for image_processing.ipynb)
pip install pillow pillow-heif rawpy imageio imageio-ffmpeg

# Optional: GPU support
pip install tensorflow-gpu
```

**Quick install (all projects):**
```bash
pip install -r requirements.txt
```

*(Create `requirements.txt` with:)*
```
tensorflow==2.13.0
opencv-python==4.8.0
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
scikit-learn==1.3.0
pandas==2.0.3
pillow==10.0.0
pillow-heif==0.12.0
rawpy==0.18.1
imageio==2.31.1
imageio-ffmpeg==0.4.9
```

#### **4. Verify Installation**
```bash
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
python -c "import cv2; print('OpenCV:', cv2.__version__)"
python -c "import numpy; print('NumPy:', numpy.__version__)"
```

---

## üìÇ Project Structure

```
CVPR/
‚îÇ
‚îú‚îÄ‚îÄ README.md                              # This file
‚îÇ
‚îú‚îÄ‚îÄ MID/                                   # Mid-term assignments
‚îÇ   ‚îú‚îÄ‚îÄ Assignment_1.ipynb                 # k-NN classifier (animal dataset)
‚îÇ   ‚îî‚îÄ‚îÄ Assignment_2.ipynb                 # Neural network from scratch
‚îÇ
‚îú‚îÄ‚îÄ FINAL/                                 # Final projects
‚îÇ   ‚îú‚îÄ‚îÄ image_processing.ipynb             # Multi-format image preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ student_attendance_system.ipynb    # CNN face recognition
‚îÇ   ‚îú‚îÄ‚îÄ student_attendance_system(Transfer_learning).ipynb  # ResNet50 face recognition
‚îÇ   ‚îî‚îÄ‚îÄ webcam_digit_detector_v2.ipynb     # Real-time digit detection
‚îÇ
‚îú‚îÄ‚îÄ dataset/                               # Raw images (create this folder)
‚îÇ   ‚îî‚îÄ‚îÄ {student_id}/                      # Student folders
‚îÇ       ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ       ‚îú‚îÄ‚îÄ image2.heic
‚îÇ       ‚îî‚îÄ‚îÄ image3.dng
‚îÇ
‚îú‚îÄ‚îÄ dataset_processed/                     # Processed images (auto-generated)
‚îÇ   ‚îî‚îÄ‚îÄ {student_id}/
‚îÇ       ‚îú‚îÄ‚îÄ 1.jpg
‚îÇ       ‚îú‚îÄ‚îÄ 2.jpg
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ models/                                # Saved models (auto-generated)
‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras
‚îÇ   ‚îú‚îÄ‚îÄ resnet50_model.keras
‚îÇ   ‚îî‚îÄ‚îÄ training_history.png
‚îÇ
‚îî‚îÄ‚îÄ attendance_logs/                       # Attendance CSVs (auto-generated)
    ‚îî‚îÄ‚îÄ attendance_20260201_143052.csv
```

---

## üíª Usage

### **üéØ MID Projects**

#### **Assignment 1: k-NN Classifier**
```bash
# 1. Open Jupyter Notebook
jupyter notebook MID/Assignment_1.ipynb

# 2. Prepare dataset
# - Upload animal_dataset.zip to /content/ (Colab)
# - Or place in MID/ directory (local)

# 3. Run all cells
# - Automatically extracts ZIP
# - Trains k-NN with K=1 to 19
# - Displays best hyperparameters
# - Shows sample predictions

# Expected Output:
# ‚úì Best Model: K=9, Metric=L1, Accuracy=41.00%
```

#### **Assignment 2: Neural Network**
```bash
# Open notebook
jupyter notebook MID/Assignment_2.ipynb

# Run all cells - no dataset required (synthetic data)
# Trains 3 models:
#   Model A: Baseline (10-10-10, lr=0.01)
#   Model B: Large (20-20-20, lr=0.01)
#   Model C: High LR (10-10-10, lr=0.05)

# Expected Output:
# ‚úì Model C achieves 100% test accuracy
```

---

### **üéì FINAL Projects**

#### **1. Image Processing Pipeline**
```bash
# Open notebook
jupyter notebook FINAL/image_processing.ipynb

# Setup:
mkdir dataset
mkdir dataset/student1
mkdir dataset/student2
# Add images to student folders

# Run all cells
# Output: dataset_processed/ folder with standardized images
```

**Supported Formats**:
```python
# Input: .jpg, .jpeg, .png, .heic, .dng
# Output: {student_id}/1.jpg, 2.jpg, 3.jpg, ...
# Size: 524√ó524 pixels, center-cropped, RGB
```

---

#### **2. Student Attendance (CNN)**
```bash
# Open notebook
jupyter notebook FINAL/student_attendance_system.ipynb

# Required folder structure:
# dataset_processed/
#   ‚îú‚îÄ‚îÄ 22-12345-1/  (at least 10 images)
#   ‚îú‚îÄ‚îÄ 22-12346-1/
#   ‚îî‚îÄ‚îÄ ...

# Run cells 1-11 for training
# Run cell 12 for live camera demo

# Camera controls:
#   'q' ‚Üí Quit and save attendance
#   's' ‚Üí Save attendance now
```

**Training Configuration**:
```python
IMG_SIZE = 128
BATCH_SIZE = 32
EPOCHS = 150
MIN_CONFIDENCE = 0.75
```

**Output Files**:
- `models/best_model.keras` ‚Üí Trained CNN
- `models/training_history.png` ‚Üí Loss/accuracy curves
- `attendance_logs/attendance_*.csv` ‚Üí Attendance records

---

#### **3. Student Attendance (Transfer Learning)**
```bash
# Open notebook
jupyter notebook FINAL/student_attendance_system\(Transfer_learning\).ipynb

# Set mode (in cell 3):
LOAD_MODEL_ONLY = False  # First run: trains model
LOAD_MODEL_ONLY = True   # Subsequent runs: loads saved model

# Training phases:
# Phase 1: Frozen ResNet50 (60 epochs)
# Phase 2: Fine-tuning (60 epochs)

# Expected results:
# ‚úì Top-1 Accuracy: ~95%
# ‚úì Top-5 Accuracy: ~99%
```

**Advanced Features**:
```python
# Model configuration
IMG_SIZE = 160  # Input size
BATCH_SIZE = 16  # Smaller for large model
EPOCHS = 120  # Split 60+60
MIN_CONFIDENCE = 0.85  # Higher threshold
```

---

#### **4. Webcam Digit Detector**
```bash
# Open notebook
jupyter notebook FINAL/webcam_digit_detector_v2.ipynb

# Option 1: Local webcam
# Run all cells (including cell 12)
# Default: cv2.VideoCapture(0)

# Option 2: IP camera (DroidCam)
# In cell 12, change:
videoCapture = cv2.VideoCapture('http://192.168.0.221:4747/video')

# Controls:
#   'Q' ‚Üí Quit

# Write digit in cyan detection box ‚Üí see prediction
```

**Demo Output**:
```
Window 1: Number Recognition System (main)
Window 2: Processed Binary (threshold view)
Window 3: Digit Preview (28√ó28)
```

---

## üìä Results & Performance

### **MID Projects**

| Assignment | Algorithm | Dataset | Accuracy | Notes |
|-----------|-----------|---------|----------|-------|
| 1 | k-NN (K=9) | Animal (1000 images) | **41.00%** | Manhattan distance outperforms Euclidean |
| 2 | 3-Layer NN | Gaussian (1000 samples) | **100%** | Model C with lr=0.05 |

### **FINAL Projects**

| Project | Model | Classes | Top-1 Acc | Top-5 Acc | Inference Time |
|---------|-------|---------|-----------|-----------|----------------|
| Attendance (CNN) | Custom CNN | 66 students | **~85%** | **~95%** | ~50ms/image |
| Attendance (ResNet50) | Transfer Learning | 66 students | **~95%** | **~99%** | ~80ms/image |
| Digit Detector | Dense NN | 10 digits | **~98%** | **~99.9%** | ~20ms/frame |

### **Key Insights**

1. **k-NN Performance**: Manhattan distance (L1) consistently outperforms Euclidean (L2) in high-dimensional image spaces due to robustness against outlier pixels.

2. **Neural Network Training**: ReLU activation is critical for deep networks (3+ layers). Sigmoid causes vanishing gradients. Learning rate (0.05) > network size for small datasets.

3. **Face Recognition**: Transfer learning (ResNet50) achieves **+10% accuracy** over custom CNN with **50% less training time**. Trade-off: larger model size (250MB vs 50MB).

4. **Real-Time Systems**: Haar Cascade detection is **5x faster** than DNN-based methods (MTCNN, SSD) but less accurate. Acceptable for controlled environments (classrooms).

---


## üî¨ Technical Deep Dive

### **1. k-NN Algorithm (From Scratch)**
```python
def knn_predict(X_train, y_train, X_test, k, metric):
    predictions = []
    for test_point in X_test:
        distances = []
        for i in range(len(X_train)):
            # Calculate L1 or L2 distance
            dist = calculate_distance(test_point, X_train[i], metric)
            distances.append((dist, y_train[i]))
        
        # Sort and take top-k
        distances.sort(key=lambda x: x[0])
        k_nearest = distances[:k]
        
        # Majority voting
        k_labels = [label for (_, label) in k_nearest]
        most_common = np.bincount(k_labels).argmax()
        predictions.append(most_common)
    
    return np.array(predictions)
```

### **2. Backpropagation (Manual Implementation)**
```python
def back_propagation(self, X, Y_true):
    N = X.shape[0]
    
    # Output layer gradient (Softmax + Cross-Entropy)
    dZ4 = (self.Y_hat - Y_true) / N  # Simplified derivative
    
    # Chain rule backwards through 3 hidden layers
    dW4 = np.dot(self.A3.T, dZ4)
    db4 = np.sum(dZ4, axis=0, keepdims=True)
    
    dA3 = np.dot(dZ4, self.W4.T)
    dZ3 = dA3 * self.relu_derivative(self.A3)
    # ... (continues for layers 2 and 1)
    
    # Gradient descent
    self.W4 -= self.learning_rate * dW4
    self.b4 -= self.learning_rate * db4
    # ...
```

### **3. CNN Architecture (Custom)**
```python
model = Sequential([
    # Block 1: Low-level features (edges, colors)
    Conv2D(32, (3,3), padding='same', activation='relu'),
    BatchNormalization(),
    Conv2D(32, (3,3), padding='same', activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2,2)),
    Dropout(0.15),
    
    # Block 2: Mid-level features (shapes, textures)
    Conv2D(64, (3,3), padding='same', activation='relu'),
    BatchNormalization(),
    Conv2D(64, (3,3), padding='same', activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2,2)),
    Dropout(0.15),
    
    # Block 3: High-level features (face parts)
    Conv2D(128, (3,3), padding='same', activation='relu'),
    BatchNormalization(),
    Conv2D(128, (3,3), padding='same', activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2,2)),
    Dropout(0.2),
    
    # Classification head
    Flatten(),
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(NUM_CLASSES, activation='softmax')
])
```

### **4. Transfer Learning (ResNet50)**
```python
# Phase 1: Frozen backbone
base_model = ResNet50(weights='imagenet', include_top=False)
base_model.trainable = False

model = Sequential([
    layers.Resizing(224, 224),
    base_model,
    GlobalAveragePooling2D(),
    Dense(512, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(NUM_CLASSES, activation='softmax')
])

# Phase 2: Fine-tuning (unfreeze last 50 layers)
base_model.trainable = True
for layer in base_model.layers[:50]:
    layer.trainable = False
```

---

## üêõ Troubleshooting

### **Common Issues**

#### **1. GPU Not Detected**
```python
# Check GPU availability
import tensorflow as tf
print(tf.config.list_physical_devices('GPU'))

# Solution 1: Install CUDA 11.2 + cuDNN 8.1
# Solution 2: Use CPU (slower but works)
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

#### **2. Out of Memory (OOM)**
```python
# Reduce batch size
BATCH_SIZE = 8  # Instead of 32

# Enable memory growth
gpus = tf.config.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)
```

#### **3. Camera Not Opening**
```python
# Windows: Check camera permissions
# Settings ‚Üí Privacy ‚Üí Camera ‚Üí Allow desktop apps

# Linux: Check device
ls /dev/video*  # Should show /dev/video0

# Mac: Grant terminal camera access
# System Preferences ‚Üí Security ‚Üí Camera
```

#### **4. DNG Files Not Processing**
```bash
# Install rawpy dependencies
pip install rawpy --upgrade

# Fallback: Convert DNG to JPG manually
# Adobe DNG Converter: https://helpx.adobe.com/camera-raw/digital-negative.html
```

#### **5. Kaggle Dataset Not Found**
```python
# Ensure dataset is uploaded as input
# Path should be: /kaggle/input/dataset-processed/

# Check structure
!ls /kaggle/input
!ls /kaggle/input/dataset-processed
```

---

## ü§ù Contributing

Contributions are welcome! Here's how:

1. **Fork the repository**
   ```bash
   git clone https://github.com/YOUR_USERNAME/CVPR.git
   ```

2. **Create a feature branch**
   ```bash
   git checkout -b feature/AmazingFeature
   ```

3. **Commit changes**
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```

4. **Push to branch**
   ```bash
   git push origin feature/AmazingFeature
   ```

5. **Open a Pull Request**

### **Contribution Ideas**
- üéØ Add support for YOLO/SSD face detection
- üéØ Implement data augmentation strategies (Mixup, CutMix)
- üéØ Add model quantization for mobile deployment
- üéØ Create Streamlit/Gradio web interface
- üéØ Add unit tests for preprocessing pipeline

---




## üë®‚Äçüíª Author

**Tanmoy**  
GitHub: [@TanmoyGG](https://github.com/TanmoyGG)  
Google Colab Notebooks: [TanmoyGG/CVPR](https://colab.research.google.com/github/TanmoyGG/CVPR/)

---

## üôè Acknowledgments

- **MNIST Dataset**: Yann LeCun et al. ([MNIST Database](http://yann.lecun.com/exdb/mnist/))
- **ResNet50**: Kaiming He et al., *Deep Residual Learning for Image Recognition* (2015)
- **Haar Cascades**: Viola-Jones object detection framework (OpenCV)
- **TensorFlow Team**: For the amazing deep learning framework
- **Kaggle Community**: For GPU resources and dataset hosting

---

## üìö References & Resources

### **Papers**
1. k-Nearest Neighbors: Cover & Hart (1967) - *Nearest Neighbor Pattern Classification*
2. Backpropagation: Rumelhart et al. (1986) - *Learning representations by back-propagating errors*
3. ResNet: He et al. (2015) - *Deep Residual Learning for Image Recognition*
4. Batch Normalization: Ioffe & Szegedy (2015) - *Batch Normalization: Accelerating Deep Network Training*

### **Tutorials**
- [TensorFlow Official Tutorials](https://www.tensorflow.org/tutorials)
- [OpenCV Face Detection Guide](https://docs.opencv.org/4.x/db/d28/tutorial_cascade_classifier.html)
- [Keras Transfer Learning](https://keras.io/guides/transfer_learning/)

### **Datasets**
- [Animal Dataset (Kaggle)](https://www.kaggle.com/datasets/animals)
- [MNIST Handwritten Digits](http://yann.lecun.com/exdb/mnist/)
- [LFW (Labeled Faces in the Wild)](http://vis-www.cs.umass.edu/lfw/)

---

## üìû Support

Having issues? Here's how to get help:

1. **Check Troubleshooting Section** (above)
2. **Search Issues**: [GitHub Issues](https://github.com/TanmoyGG/CVPR/issues)
3. **Open New Issue**: Provide error logs, Python version, OS details
4. **Email**: Create an issue for direct support

---



## üìà Project Stats

```
Total Lines of Code: ~5,000+
Notebooks: 6
Models Implemented: 5 (k-NN, NN, CNN, ResNet50, Dense)
Dataset Size: 1,000+ images (66 classes)
Training Time: ~2 hours (GPU) | ~8 hours (CPU)
Accuracy Range: 41% (k-NN) ‚Üí 98% (ResNet50)
```

---

## ‚≠ê Star History

If you find this project helpful, please consider giving it a ‚≠ê on GitHub!

[![Star History Chart](https://api.star-history.com/svg?repos=TanmoyGG/CVPR&type=Date)](https://star-history.com/#TanmoyGG/CVPR&Date)

---

<div align="center">

**Made with ‚ù§Ô∏è by Tanmoy**

*Computer Vision ‚Ä¢ Deep Learning ‚Ä¢ Real-Time Systems*

[‚¨Ü Back to Top](#-computer-vision--pattern-recognition---complete-project-suite)

</div>